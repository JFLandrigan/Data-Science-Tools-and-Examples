---
title: "Prediction Using Regression"
author: "Jon Landrigan"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This is an example work flow for building a regression model in R. The dataset that will be used in this example is available for download at https://www.kaggle.com/uciml/autompg-dataset. This dataset contains the techinical specs for cars. 

First I will load the packages that will be used to run the analyses.
```{r, message = FALSE}
#Load the data set 
library(boot)
library(ggplot2)
```

Now I will read in the data file. Note you can also use read.csv to read in the data to R.
```{r}
cardat <- read.table('auto-mpg.csv', sep = ',', header = TRUE)
```

Now lets get some basic info about the data set using the summary and str functions
```{r}
summary(cardat)
```

```{r}
str(cardat)
```

Most of the data looks fine with the exception of horsepower. We would expect this to be an int or numeric but it is showing up as a factor. Closer inspection of the str output shows that there are '?' present in the dataset. This was most likely used to code for missing data so we will replace the '?' with NA and then convert this column from factor to numeric. 
```{r}
cardat$horsepower[cardat$horsepower == '?'] <- NA
cardat$horsepower <- as.numeric(as.character(cardat$horsepower))
```

Lets check to make sure that the '?' were removed and that the column has been converted to a numeric.
```{r}
str(cardat)
```

Now I'll check to see if there is any missing data present in the dataset 
```{r}
colSums(is.na(cardat))
```

As can be seen there are 6 missing values in the horsepower column. There are two options that we can use to fix this issue. The first which is the simplet is to just remove these observations from the data set. The second option would be to fill in the missing data with multiple imputations, however as multiple imputations is a little beyond the scope of this example work flow I am just going to remove the missing values. 
```{r}
cardat <- na.omit(cardat)
dim(cardat)
```

The original dimensions of the dataset was 398 rows by 9 columns. and as we can see there are now 392 rows means that na.omit dropped the 6 observations that were missing data. Note that had I not converted the '?' to NA values the na.omit function would not have worked.


For this example I will try and predict the MPG for a given car based on the other features. 
Since I am trying to predict the MPG first I will visualize the data to see which predictors appear to have a relationship with MPG. There are a number of methods for doing this but I primarily like to use ggplot for all my plotting. 

The first plot is a bar plot looking at the mean mpg by cylinders. Note because cylinders is an int value I changed it to a factor so that the cylinder values would be categorical as opposed to conintous. 
```{r}
ggplot(cardat, aes(x = as.factor(cylinders), y = mpg)) +
  stat_summary(fun.y='mean',geom = 'bar', position = 'dodge') +
  stat_summary(fun.data = 'mean_se', geom = 'errorbar', position = position_dodge(width = 0.9), width = .4)
```

Now lets take a look at the relationship between mpg and horsepower 
```{r}
ggplot(cardat, aes(x = horsepower, y = mpg)) + geom_point() + geom_smooth(method='lm',formula = y~x)
```

It appears that there is a relationship however a simple linear line does not appear to capture the exact relationship. Lets see if polynomials fit the data better. 
```{r}
ggplot(cardat, aes(x = horsepower, y = mpg)) + geom_point() + 
  geom_smooth(method='lm', formula = y~x, colour = 'red') +
  geom_smooth(method='lm', formula = y ~ poly(x, 2, raw=TRUE), colour = 'blue') +
  geom_smooth(method='lm', formula = y ~ poly(x, 3, raw=TRUE), colour = 'green')

```

As can be seen the quadratic and cubic terms both fit the data better then the linear term. 

Now lets do the same for the relationship between accelaration and mpg
```{r}
ggplot(cardat, aes(x = acceleration, y = mpg)) + geom_point() + 
  geom_smooth(method='lm', formula = y~x, colour = 'red') +
  geom_smooth(method='lm', formula = y ~ poly(x, 2, raw=TRUE), colour = 'blue') +
  geom_smooth(method='lm', formula = y ~ poly(x, 3, raw=TRUE), colour = 'green')
```
Unfortunately it does not appear that there is a clear relationship between acceleration and mpg. 

Finally lets do this for weight and mpg. 
```{r}
ggplot(cardat, aes(x = weight, y = mpg)) + geom_point() + 
  geom_smooth(method='lm', formula = y~x, colour = 'red') +
  geom_smooth(method='lm', formula = y ~ poly(x, 2, raw=TRUE), colour = 'blue') +
  geom_smooth(method='lm', formula = y ~ poly(x, 3, raw=TRUE), colour = 'green')
```

Just as with the relaitonship between horsepower and mpg it appears that the higher order polynomial terms fit the data better then the simple linear term. 

We could continue to do this for all the predictors but given that this is a simple example we will now move on to fitting a model.

First I will define the model with mpg as the outcome and horsepower and weight as the predictors. Note that since the higher order polynomials appeared to fit the data better we will use those terms in the regression model as opposed to the simple linear terms. I will start by using the third order polynomials.
```{r}
lm.mod = glm(mpg ~ poly(horsepower, 3) + poly(weight, 3), data = cardat)
```

We can get a summary of the terms using the summary function
```{r}
summary(lm.mod)
```

From the summary of the model fit we can see that neither of the cubic terms were significant predictors of mpg so lets just use the quadratic term.
```{r}
lm.mod = glm(mpg ~ poly(horsepower, 2) + poly(weight, 2), data = cardat)
summary(lm.mod)
```

Now using the cv.glm function provided by the boot package I will perform 10-fold cross-validation to see how well the model performs in generalizing to data that it has not seen before or in other words how good the model is at predicting mpg. 
```{r}
cv.err = cv.glm(cardat, lm.mod, K = 10)
```

cv.glm returns a list wich contains 4 peices. The most important element in this list is delta. Delta is a vector of length two. The first element in this vector is the raw cross-validation estimate of the prediction error. The second element is the adjusted cross-validation estimate of the prediction error which is designed to compensate for the bias introduced by not using leave-one-out cross-validation. 
```{r}
cv.err$delta
```

We see that the Mean Squared Error for the model is 15.58 and therfore for the Root Mean Square Error of the model is 3.94. Given that the range of mpg is 9 to 46.60, a mean rmse of 3.94 is pretty good. 